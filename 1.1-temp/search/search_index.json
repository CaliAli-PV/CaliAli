{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to CaliAli Documentation (Deprecated, please go to latest version)","text":""},{"location":"#introduction","title":"Introduction","text":"<ul> <li> <p>About CaliAli</p> <ul> <li>Key Features</li> <li>Version History</li> <li>License</li> <li>Questions about CaliAli?</li> </ul> </li> <li> <p>Installation and system requirements</p> <ul> <li>System Requirement<ul> <li>Hardware</li> <li>Others</li> </ul> </li> <li>Installation</li> </ul> </li> </ul>"},{"location":"#pipeline-step-by-step","title":"Pipeline step-by-step","text":"<p>Note</p> <p>Already familiar with the documentation? Get a quick overview of the functions you need to run in the TL;DR section.</p> <ul> <li> <p>Getting Started</p> <ul> <li>CaliAli processing steps</li> </ul> </li> <li> <p>Downsampling and Motion Correction</p> <ul> <li>Downsampling and Conversion to .h5 Format</li> <li>Motion Correction</li> </ul> </li> <li> <p>Inter-Session Alignment</p> <ul> <li>Evaluate Alignment Performance</li> <li>Processing Sessions without Concatenation</li> </ul> </li> <li> <p>Calcium Signal Extraction with CaliAli</p> <ul> <li>Select Extraction Parameters</li> <li>Adjusting PNR and Corr. Thresholds</li> <li>Extracting Calcium Signals</li> </ul> </li> <li> <p>Post-processing</p> <ul> <li>Monitoring Extracted Components</li> <li>Sort spatial Components</li> <li>Deleting and Merging Components</li> <li>Picking Neurons from Residual</li> </ul> </li> </ul>"},{"location":"#others","title":"Others","text":"<ul> <li> <p>Utilities</p> <ul> <li>Reproducing Video Data in .h5 Format</li> <li>Monitoring Extracted Calcium Transients</li> <li>Separate Data from Different Sessions</li> <li>Other Functions</li> </ul> </li> <li> <p>TL;DR</p> </li> </ul>"},{"location":"Intro/","title":"About CaliAli","text":"<p>CaliAli is a comprehensive suite designed for extracting neural signals from one-photon calcium imaging data collected across multiple sessions in free-moving conditions. CaliAli incorporates all the necessary modules to extract long-term tracked calcium signals from raw video sessions.</p> <p></p>"},{"location":"Intro/#key-features","title":"Key Features","text":"<p>CaliAli includes the following functions:</p> <ul> <li>Downsampling Videos: Provides functions for downsampling videos.</li> <li>Motion Correction: Corrects rigid and non-rigid motion artifacts within the field of view.</li> <li>Automatic Detrending and Preprocessing: CaliAli automatically preprocesses sessions to prepare them for concatenation in subsequent steps.</li> <li>Alignment of Sessions: Aligns multiple calcium imaging sessions using blood vessel projections obtained from motion-corrected calcium imaging videos.</li> <li>Neural Signal Extraction: Offers a graphical user interface (GUI) to estimate optimal neural extraction parameters and customize the CNMF-E pipeline for extracting calcium signals from long, concatenated video sequences.</li> <li>Post-processing and Evaluation: Provides a GUI for easy labeling and identification of false positives.</li> <li>Manual Extraction of Missed Neurons: Offers a GUI for examining residual images and allowing users to choose new seed pixels to re-execute the extraction process.</li> <li>Several other functions that facilitate video monitoring and calcium signal tracking throughout the extraction process.</li> </ul>"},{"location":"Intro/#version-history","title":"Version History","text":""},{"location":"Intro/#caliali-101-release-notes","title":"CaliAli 1.0.1 Release Notes","text":"<p>April 22nd 2024</p> <ul> <li>Introduced a new app for determining optimal blood vessel (BV) size.</li> <li>Removed unnecessary or deprecated functions.</li> <li>Several improvements to the documentation.</li> </ul> <p>Full Changelog on GitHub.</p>"},{"location":"Intro/#caliali-stable-version-10-release-notes","title":"CaliAli Stable Version 1.0 Release Notes","text":"<p>April 19th 2024</p> <p>We are excited to announce the first stable version of CaliAli, featuring significant enhancements and improvements. Below are the key changes in this release:</p> <p>Changes:</p> <ul> <li> <p>Full Online Documentation: Access comprehensive documentation to guide you through using CaliAli efficiently.</p> </li> <li> <p>Optimized Computational Performance: CaliAli is now optimized for low memory requirements, ensuring smoother and more efficient processing.</p> </li> <li> <p>Improved Session Analysis: Analyze individual sessions and perform multisession concatenation seamlessly.</p> </li> <li> <p>Enhanced Blood Vessel (BV) Extraction: Minimized vignetting artifacts for improved accuracy in BV extraction.</p> </li> <li> <p>New BV Stability Metric: Evaluate tracking performance with a new stability metric integrated into BV extraction.</p> </li> <li> <p>Bug Fixes in GUIs: Addressed several bugs in the graphical user interfaces (GUIs) for improved usability.</p> </li> <li> <p>Enhanced Inter-Session Alignment: Further improvements to the inter-session alignment module for precise video session alignment.</p> </li> </ul> <p>Full Changelog on GitHub.</p>"},{"location":"Intro/#caliali-beta-release-10-beta","title":"CaliAli Beta Release 1.0-beta","text":"<p>May 19th 2023</p> <p>The first beta release of CaliAli is now available, offering advanced capabilities for extracting neural signals from one-photon calcium imaging data in free-moving conditions.</p> <p>For details, refer to the BioRxiv preprint.</p> <p>Explore CaliAli to analyze calcium imaging data with accuracy and efficiency, shaping the future of neural signal extraction in neuroscience research.</p>"},{"location":"Intro/#gnu-general-public-license-v30","title":"GNU General Public License v3.0","text":"<p>CaliAli License</p> <p> CaliAli-PV/CaliAli is licensed under the GNU General Public License v3.0.</p> <p>Permissions of this strong copyleft license are conditioned on making available complete source code of licensed works and modifications, which include larger works using a licensed work, under the same license. Copyright and license notices must be preserved. Contributors provide an express grant of patent rights</p> <ul> <li> <p>Permissions  (1)</p> <ol> <li> <ul> <li>Commercial use </li> <li>Modification </li> <li>Distribution </li> <li>Patent use </li> <li>Private use </li> </ul> </li> </ol> </li> <li> <p>Limitations  (1)</p> <ol> <li> <ul> <li>Liability </li> <li>Warranty </li> </ul> </li> </ol> </li> <li> <p>Conditions (1)</p> <ol> <li> <ul> <li>License and copyright notice: Must be preserved</li> <li>State changes: Must disclose changes made</li> <li>Disclose source: Source code must be made available</li> <li>Same license: Modifications must be licensed under the same terms</li> </ul> </li> </ol> </li> </ul>"},{"location":"Intro/#questions-about-caliali","title":"Questions about CaliAli?","text":"<p>We're currently developing a comprehensive Frequently Asked Questions (FAQ) section for CaliAli, coming soon! In the meantime, please don't hesitate to reach out on our discussion board if you have any questions or need assistance.</p> Next <p>Proceed to Installation and system requirements</p>"},{"location":"Post/","title":"Post-Processing","text":"<p>CaliAli incorporates a GUI to facilitate the identification of false-positive detections. </p> <p>After loading the <code>neuron</code> object stored in the Checkpoint files, execute the following function to call this GUI:</p> <pre><code>ix=postprocessing_app(neuron);\n</code></pre>"},{"location":"Post/#monitoring-extracted-components","title":"Monitoring Extracted Components","text":"<p>The post-processing app will display the correlation image with overlaid contours of the detected neurons. Clicking on these contours will show the corresponding extracted calcium transients:</p> <p></p> <p>You can hold you mouse to zoom:</p> <p></p> <p>You can reset the zoom and clear the neuronal selection by pressing the buttons located above the correlation image:</p> <p></p> <p>You can label false positives by right-clicking on the neuron contours:</p> <p></p>"},{"location":"Post/#sort-spatial-components","title":"Sort Spatial Components","text":"<p>CaliAli can label false positives based on the shape of the extracted spatial components. To accomplish this, CaliAli incorporates a tool that sorts spatial components by their spatial congruence. To utilize this function, press the 'Separate Spatial' button.</p> <p>This will open a panel displaying all the extracted spatial components. Components with congruent shapes are sorted at the beginning, while neurons with shapes different from the rest of the population are sorted last. Components labeled as false-positives will be listed on the right.</p> <p></p> <p>Note that elongated components, which could correspond to neuropil signals rather than neuron somas, appear at the bottom of the list. You can select these components and move them to the false-positive panel.</p> <p></p> <p>Once satisfied with the selections press the <code>Done!</code> button.</p> <p>This will label the component as false-positive in the correlation image. </p>"},{"location":"Post/#deleting-and-merging-components","title":"Deleting and Merging Components","text":"<p>Once you finish labeling false-positive in the main App press the <code>Done!</code> button.</p> <p>This will create a variable <code>ix</code> holding the indices of the labeled false-positives.</p> <p>You can delete these components by running <code>neuron.delete(ix);</code>. Alternatively, you can monitor each of these components with <code>neuron.viewNeurons(find(ix), neuron.C_raw);</code>.</p> <p>After deleting false positives, you can consider merging neurons by manually monitoring neurons that are close by. For this, run<code>neuron.merge_high_corr(1, [0.1, 0.3, -inf]);</code></p> Tip <p>Note that you can save your results at any point running <code>save_workspace(neuron);</code></p>"},{"location":"Post/#picking-neurons-from-residual","title":"Picking Neurons from Residual","text":"<p>Some neurons may remain unextracted after the initial processing. To extract potentially missed neurons run: <code>neuron=manually_update_residuals(neuron,use_parallel);</code></p> <p>This will open a GUI displaying the PNR, Corr., and PNR*Corr. images(1). These images will be shown in their original form (top panels) and also after subtracting the current neuron detections from the video (Residual video) (bottom panels).</p> <ol> <li>Refer to Select Extraction Parameters for a description of the PNR, Corr. and PNR*Corr images.</li> </ol> <p>Here, you can manually add initialization seeds for undetected neurons. Clicking on any of these images will place a red dot that initializes these neurons:</p> <p></p> <p>This will initialize these neurons and repeat the CNMF process required to extract the Calcium signals.</p> <p>After extracting the residual data, you may want to consider redoing the post-processing step described earlier</p> Tip <p>In most cases picking neurons is not necessary.</p> Info <p>If you ever change the location of the videos and files generated during the analysis be sure to run this steps after</p> <p>CONGRATULATIONS!: You have successfully extracted neuronal signals using CaliAli. Don't forget to save the results with <code>save_workspace(neuron)</code></p> Next <p>We recommend checking the Utilities  included with CaliAli.</p>"},{"location":"Prep/","title":"Downsampling and Motion correction","text":""},{"location":"Prep/#i-downsampling-and-conversion-to-h5-format","title":"I. Downsampling and Conversion to .h5 Format","text":"<p>The first step in the CaliAli pipeline is to convert the raw video format into the .h5 format used by CaliAli. This step is done together with spatial downsampling.</p> <p>Temporal downsampling</p> <p>CaliAli currently does not support temporal downsampling. Use alternative methods prior to running these steps.</p> <p>The function used to downsample video sessions would depende on the format of the source data:</p>"},{"location":"Prep/#syntax","title":"Syntax:","text":".avi / .m4v / .mp4.tiff.isdx (Inscopix) <p><pre><code>Downsample_avi(ds_f, outpath, theFiles) \n</code></pre> This function reads AVI video files, downsamples them, and saves the resulting frames as an HDF5 (.h5) file.</p> <p>Windows Users: Please note the following system-specific instructions</p> <p>Matlab does not have the necessary codecs to process <code>.avi</code> files in windows. You need to download and install the K-lite Codec Pack to be able to run this code.</p> <p><pre><code>Downsample_tiff(ds_f, outpath, theFiles)        \n</code></pre> This function reads tiff video files, downsamples them, and saves the resulting frames as an HDF5 (.h5) file.   </p> <p><pre><code>Downsample_Inscopix(ds_f, outpath, theFiles)\n</code></pre> This function reads Inscopix video files, downsamples them, and saves the resulting frames as an HDF5 (.h5) file.</p> <p>Inscopix Users: Please note the following system-specific instructions</p> <p>Note that this requires installing the Inscopix Data Processing software.  By default this function search for the Inscopix path in 'C:\\Program Files\\Inscopix\\Data Processing'. If this path is not found, a folder selection dialog box will be called.</p>"},{"location":"Prep/#input-arguments","title":"Input Arguments:","text":"<ul> <li>ds_f (optional): Downsampling factor. Default is 1 (no downsampling).</li> <li>outpath (optional): Output path for saving downscaled video files. If not provided, the files will be saved in the same directory as the input files.</li> <li>theFiles (optional): Cell array containing paths to video files. If not provided, a file picker dialog will open to select video files interactively.   </li> </ul>"},{"location":"Prep/#example-usage","title":"Example Usage:","text":"<pre><code>% Downsampling AVI files with a downsampling factor of 2\nDownsample_avi(2);\n\n% Do not Downsample AVI files and specifying an output path\nDownsample_avi(1, 'C:\\Output');\n\n% Downsampling specific AVI files\nfiles = {'video1.avi', 'video2.avi'};\nDownsample_avi(2, 'C:\\Output', files);\n</code></pre> Which downsampling factor should I use? <p>We recommend using a 4x factor for Inscopix videos and 2x for UCLA miniscope V4 videos.</p> <p></p> How can I play .h5 videos? <p>You can monitor <code>.h5</code> data using the following function: Play video data in .h5 format </p>"},{"location":"Prep/#ii-motion-correction","title":"II. Motion Correction","text":"<p>Following video downsampling, it is necessary to correct motion artifacts in each individual session.</p> <p>For this we use the following function. <pre><code>MC_Batch(theFiles, do_nr, varargin);\n</code></pre> The MC_Batch function processes a group of .h5 video files by applying motion correction techniques and saving the corrected videos to new HDF5 files.</p> About the _mc suffix <p>The output files will be suffixed with <code>_mc</code>. This suffix is necessary for subsequent modules to recognize files that have already undergone motion correction. </p> How long it takes to motion correct videos? <p>The motion correction process is relatively slow. A 10-minute video would be processed in 10 minutes. (1).</p> <ol> <li>~9 frames per second at a resolution of 300x300 pixels, using a 24-core processor (AMD Ryzen Threadripper 3960X). </li> </ol>"},{"location":"Prep/#input-arguments_1","title":"Input Arguments:","text":"<ul> <li>theFiles (optional): Cell array containing paths to video files. If <code>[]</code> is provided, a file picker dialog will open to select video files interactively.</li> <li>do_nr: (optional) Logical flag indicating whether to perform non-rigid motion correction (1 for yes, 0 for no). Default is 1.</li> <li>gSig: Neuron Filter size (aprox. 1/4 of the nueron size in px). Default is 2.5 .</li> <li>sf: Frame rate. Default is 10 fps.</li> <li>BVz: Size of blood vessels [min diameter max diameter] in pixels. Defaults is [0.6gSig, 0.9gSig].</li> </ul>"},{"location":"Prep/#example-usage_1","title":"Example Usage:","text":"<p><pre><code>% Manually choose files and perform non-rigid motion correction. Set a frame rate of 15fps\nMC_Batch([], 1,'sf',15);\n\n% Manually choose files and perform rigid motion correction. Use a neuron Filter size of 3. \nMC_Batch([], 0,'gSig',3);\n\n% Manually choose files and perform non-rigid motion correction. Use custom blood vessels size (not recommended).\nMC_Batch([], 1,'BVz'[2,3]);\n</code></pre> </p> Important <p>Ensure to visually inspect the motion-corrected video before proceeding to the next step. Play video data in .h5 format</p> Next <p>After finishing downsampling and motion correction you can proceed to Inter-session Alignment</p> FAQ <p>Why do we need to specify frame rate? (1).</p> <ol> <li>The motion correction module divides the data into smaller batches to accelerate the registration process. CaliAli uses the frame rate to calculate these segments.</li> </ol> <p>Why do we need to specify nueron filter size and blood vessels size(1).</p> <ol> <li>Neuron filter size is used to approximate the size of features within the field of view. For motion correction, this estimation is employed to determine the size of blood vessels, typically ranging from 0.6gSig to 0.9gSig in diameter. Users have the option to specify a different range of blood vessel diameters; in such cases, the parameter gSig becomes unnecessary.</li> </ol> <p>Can I use other motion correction modules other than CaliAli? (1).</p> <ol> <li>Not recommended. Certain motion correction algorithms, like NoRMCorre, may introduce vertical and horizontal artifacts at the concatenation point between patches, which can affect blood vessel extraction. Adjusting the BVz parameter may resolve these issues. If you are using different modules, remember to manually append the _mc suffix to the corrected files. After motion correction, all sessions should maintain consistent XY dimensions. Any padding borders should be filled with zeros.</li> </ol>"},{"location":"TLDR/","title":"TL;DR: Processing Multi-session Calcium Imaging Data with CaliAli","text":"<p>This section is intended for users who have already read the rest of the documentation and want a general overview of the commands needed to fully process the data.</p> <p>Run the following functions:</p> <p>Note</p> <p>The following functions use the default parameters assuming a frame rate of 10 frames per second.</p>"},{"location":"TLDR/#1-data-downsampling","title":"1) Data Downsampling:","text":".avi / .m4v / .mp4.tiff.isdx (Inscopix) <pre><code>Downsample_avi(2)   \n</code></pre> <pre><code>Downsample_tiff(2)      \n</code></pre> <pre><code>Downsample_Inscopix(4)\n</code></pre>"},{"location":"TLDR/#2-motion-correction","title":"2) Motion Correction:","text":"<pre><code>% Choose the files to motion correct\nMC_Batch();\n</code></pre>"},{"location":"TLDR/#3-inter-session-alignment","title":"3) Inter-session Alignment:","text":"<pre><code>% Choose the sessions to align:\nalign_sessions_CaliAli();\n\n% If it is only one session:\ndetrend_batch_and_calculate_projections()\n</code></pre>"},{"location":"TLDR/#4-calcium-traces-extraction","title":"4) Calcium Traces Extraction:","text":"<ul> <li>Run <code>CNMFe_app</code>.</li> <li>Choose the video file with the concatenated data named <code>&lt;File_name&gt;_Aligned.h5</code> or individual sessions named <code>&lt;File_name&gt;_det.h5</code>.</li> <li>Select appropriate initialization parameters.</li> <li>Run <code>CNMFe_batch(parin)</code>.</li> </ul>"},{"location":"TLDR/#5-optional-post-processing","title":"5) Optional post-processing","text":"<ul> <li>Load the <code>.mat</code> file with the extracted data.</li> <li>Label false positives with <code>ix=postprocessing_app(neuron)</code> </li> <li>Run <code>neuron.delete(ix)</code> to check and delete labeled components. </li> <li>Run <code>save_workspace(neuron)</code> to save results.</li> </ul>"},{"location":"Usage/","title":"Installation and system requirements","text":""},{"location":"Usage/#system-requirement","title":"System Requirement","text":"<p>CaliAli runs in <code>MATLAB</code> and requires the following toolbox: <pre><code>-   Signal Processing Toolbox\n-   Image Processing Toolbox\n-   Statistics and Machine Learning Toolbox'\n-   Parallel Computing Toolbox\n</code></pre></p> Function requiring MATLAB 2023b <p>One of the utilities included in CaliAli requires 'MATLAB 2023b' due to its use of new functions from MATLAB's AppDesigner. This function is NOT essential for running the CaliAli pipeline.\"</p>"},{"location":"Usage/#windows","title":"Windows","text":"<p>CaliAli has been successfully tested on MATLAB versions 2022a and 2023a running on Windows 11.</p> MATLAB 2024a is not compatible with CaliAli on Windows <p>A bug in the 2024a AppDesigner is causing GUI objects to be improperly located within the app's panels, and it is also affecting other functions. This issue does not affect macOS MATLAB or Windows MATLAB 2023b.</p> <p>??? note \"Process Inscopix data on \u201cWindows     To process Inscopix data, the Inscopix Data Processing software needs to be installed. </p> Process UCLA miniscope data on Windows <p>MATLAB does not have the necessary codecs to process compressed .avi files. You need to download and install the K-lite Codec Pack.</p>"},{"location":"Usage/#macos","title":"MacOs","text":"<p>CaliAli has been successfully tested on MATLAB 2024a running on macOS Sonoma 14.5. </p> Process Inscopix data on Mac <p>At present, CaliAli is unable to convert Inscopix '.isdx' data into '.h5' format on ARM machines. Please convert your data into a compatible format (.h5 , uncompressed avi, or .tiff) using the Inscopix software. </p> Process UCLA miniscope data on MAC <pre><code>MATLAB cannot process compressed avi format. Be sure to save your videos in uncompressed format  or TIFF.\n</code></pre> <p>\u201c</p>"},{"location":"Usage/#linux","title":"Linux","text":"<p>CaliAli has not been tested on linux. No anticipated compatibility issues are expected.</p>"},{"location":"Usage/#hardware","title":"Hardware","text":"<p>CaliAli automatically runs in batch mode, requiring only sufficient RAM to handle the largest imaging session and storing final outputs (less than 2GB if the largest session is 180x260 pixels and 3000 frames).</p>"},{"location":"Usage/#installation","title":"Installation","text":"<p>Installation should take a few minutes:</p> <ul> <li>Download/clone the Git repository of the codes</li> <li>Add CaliAli to the MATLAB path.</li> </ul> <p></p> Next <p>Already installed? Proceed to Getting started</p>"},{"location":"Utilities/","title":"Utilities","text":""},{"location":"Utilities/#reproducing-video-data-in-h5-format","title":"Reproducing Video Data in .h5 Format","text":"<p>To reproduce video data in <code>.h5</code> format, use the <code>view_Ca_video()</code> function and select the desired <code>.h5</code> file for monitoring(1).</p> <ol> <li>Code modified from Joao Henriques (2024). Figure to play and analyze videos with custom plots on top , MATLAB Central File Exchange. </li> </ol> <p></p> <p>This app includes the following functionalities:</p> <ul> <li>Enter   Play/Stop the video.</li> <li>Backspace    Play/Stop the video at 3x speed.</li> <li>Left/Right   Advance/go back one frame. Alternatively, you can use the scroll bar at the bottom of the screen.</li> <li>Page Down/Page Up   Advance/go back 30 frames.</li> <li>C   Adjust contrast settings in the video.</li> </ul> Bug <p>When adjusting the contrast of the video, avoid using the <code>Adjust contrast</code> button. Instead, simply close the window by clicking the <code>[x]</code> button at the upper right corner of the screen.</p>"},{"location":"Utilities/#monitoring-extracted-calcium-transients","title":"Monitoring Extracted Calcium Transients","text":"<p>CaliAli includes an app to plot the extracted calcium signals. After loading the <code>neuron</code> object, run <code>view_traces(neuron)</code>.</p> <p></p> <p>This app includes the following functionalities:</p> <ul> <li>Left / Right    Scroll back or forward. Alternatively, you can use the scroll bar at the bottom of the screen.</li> <li>Use the vertical scroll bar to navigate through traces.</li> <li>Ctrl+Up / Ctrl+Down Increase/decrease the number of traces being displayed. </li> <li>Ctrl+Right / Ctrl+Left  Increase/decrease the temporal resolution.</li> <li>Use the mouse scroll wheel to change the vertical zoom.</li> <li>Press the <code>C</code> button to plot the denoised traces.</li> <li>Press the <code>S</code> button to plot the predicted rising events.</li> </ul>"},{"location":"Utilities/#app-for-optimal-blood-vessel-size-determination","title":"App for Optimal Blood Vessel Size Determination","text":"<p>Users can determine the optimal blood vessel size using <code>BV_app()</code>.</p> <p></p> <p>Control the sliders to define the minimum and maximum blood vessel width (in pixels).  After pressing <code>Done</code>, the chosen blood vessel sizes will be printed in the command window.  You can use these blood vessel sizes in other CaliAli functions by specifying the input pairs <code>'BVz'</code> and <code>[min, max]</code>.</p> When should I change the default blood vessels size? <p>In many cases, the default blood vessel size yields satisfactory results. However, in certain preparations, horizontal or vertical artifacts may appear in the field of view. The Hessian filter approach used to enhance blood vessels could also extract these structures, which might hinder subsequent inter-session alignment. Customizing the blood vessel size could help avoid these issues.</p>"},{"location":"Utilities/#separate-data-from-different-sessions","title":"Separate Data from Different Sessions","text":"<p>Separates data into sessions based on frame information and optionally bins the data.</p>"},{"location":"Utilities/#syntax","title":"Syntax:","text":"<pre><code>S = separate_sessions(data, F, bin, sf)\n</code></pre>"},{"location":"Utilities/#description","title":"Description:","text":"<p>This function separates data into sessions based on provided frame information (F). If F is not provided, the function prompts the user to select a file containing frame data. The data can be optionally binned using the specified bin size (bin) and sampling frequency (sf).</p>"},{"location":"Utilities/#inputs","title":"Inputs:","text":"<ul> <li> <p>data: Matrix of data to be separated into sessions.</p> </li> <li> <p>F (optional): Frame information used to define intervals for separating sessions. If not provided, the user will be prompted to select a file.</p> </li> <li> <p>bin (optional): Bin size for binning the data. If set to 0, no binning is applied. Default is 0 if not specified.</p> </li> <li> <p>sf (optional): Sampling frequency used when binning the data. Default is 1 if not specified.</p> </li> </ul>"},{"location":"Utilities/#outputs","title":"Outputs:","text":"<ul> <li>S: Cell array containing separated session data.</li> </ul>"},{"location":"Utilities/#example-usage","title":"Example Usage:","text":"<pre><code>% Separate spike data with default bin size and sampling frequency (no binning)\nS=separate_sessions(neuron.S, neuron.CaliAli_opt.F);\n\n% Separate spike data with 1s bin considering Sampling frequency of 10.\nS=separate_sessions(neuron.S, neuron.CaliAli_opt.F,1,10);\n\n% Separate raw Calcim traces data with default bin size and sampling frequency (no binning)\nS=separate_sessions(neuron.C_raw, neuron.CaliAli_opt.F);\n</code></pre>"},{"location":"Utilities/#other-functions","title":"Other Functions","text":""},{"location":"Utilities/#save-workspace","title":"Save Workspace","text":"<pre><code>save_workspace(neuron);\n</code></pre>"},{"location":"Utilities/#updating-paths-for-video-and-mat-files","title":"Updating Paths for Video and MAT Files","text":"<p>If you've changed the location of the videos and files generated during the analysis, you'll need to run the following function and select the new 'source_extraction' folder.</p> <pre><code> neuron=update_folder_path(neuron);\nsave_workspace(neuron);\n</code></pre>"},{"location":"Utilities/#plot-neuron-contours","title":"Plot Neuron Contours","text":"<pre><code>%% To visualize neurons contours:\nneuron.Coor=[]  \n\n%% Plot over PNR image:\n   neuron.show_contours(0.9, [], neuron.PNR, 0);  %PNR\n\n%% Plot over correlation image:\n   neuron.show_contours(0.6, [], neuron.Cn,0);   %CORR\n\n%% Plot over PNR.Corr image:\n  neuron.show_contours(0.6, [], neuron.Cn.*neuron.PNR,0); %PNR*CORR\n\n%% Plot over neuron footprints:\n A=neuron.A;A=full(A./max(A,[],1)); A=reshape(max(A,[],2),[size(neuron.Cn,1),size(neuron.Cn,2)]);\n neuron.show_contours(0.6, [], A, 0);\n</code></pre>"},{"location":"alignment/","title":"Inter-session Alignment","text":"<p>After motion correction of each session, they need to be aligned and concatenated. To achieve this, CaliAli performs the following steps:</p> <ol> <li> <p>Detrend each imaging session: This step involves removing part of the background fluorescence fluctuation.</p> </li> <li> <p>Calculate projections of the blood vessels and neurons: Projections are computed to assist in subsequent alignment steps.</p> </li> <li> <p>Calculate displacement fields to align sessions using blood vessels and neurons: Displacement fields are computed to accurately align the sessions.</p> </li> <li> <p>Apply displacement field to each video session: This step involves applying the calculated displacement field to align the video sessions.</p> </li> <li> <p>Ensure standardized pixels: Standardize pixels across sessions to the same baseline and noise level.</p> </li> <li> <p>Concatenate videos: Finally, the aligned and standardized video sessions are concatenated to create a continuous sequence.</p> </li> </ol> <p>These steps are executed collectively by executing the following function:</p>"},{"location":"alignment/#syntax","title":"Syntax:","text":"<pre><code>    align_sessions_CaliAli(Name,Value)\n</code></pre>"},{"location":"alignment/#input-arguments","title":"Input Arguments:","text":"<ul> <li>gSig: Neuron Filter size (aprox. 1/4 of the nueron size in px). Default is 2.5 .</li> <li>sf: Frame rate. Default is 10 fps.</li> <li>BVz: Size of blood vessels [min diameter max diameter] in pixels. Defaults is [0.6gSig, 0.9gSig].</li> <li>n_enhanced: Logical flag indicating whether to use MIN1PIE background subtraction (1 for yes, 0 for no). The default value is 1</li> <li>theFiles: Cell array containing paths to input video files. Default is to choose interactively.</li> </ul>"},{"location":"alignment/#example-usage","title":"Example Usage:","text":"<p><pre><code>% Align video sessions with default parameters. Manually select video sessions\nalign_sessions_CaliAli();\n\n% Align video sessions with custom neuron filter size and frame rate\nalign_sessions_CaliAli('gSig', 3, 'sf', 15);\n\n% Align video sessions with MIN1PIE background subtraction disabled and specific input video files\nvideoFiles = {'path/to/video1.avi', 'path/to/video2.avi'};\nalign_sessions_CaliAli('n_enhanced', 0, 'theFiles', videoFiles);\n\n% Align video sessions with specified blood vessel size\nalign_sessions_CaliAli('BVz', [5 20]);\n\n% Align video sessions with custom parameters:\nalign_sessions_CaliAli('gSig', 3, 'sf', 15, 'n_enhanced', 0, 'BVz', [5 20]);\n</code></pre> </p> Important <p>The order in which sessions are concatenated is determined by the order in which session are listed!   For example, the followin code would align session 2 before session 1: <pre><code>videoFiles = {'path/to/session2.avi', 'path/to/session1.avi'};\nalign_sessions_CaliAli('theFiles', videoFiles);\n</code></pre></p> About the _mc suffix <p>The <code>align_sessions_CaliAli()</code> function only detects files with the <code>_mc.h5</code> suffix. If you delete this suffix, the files will not be detected.</p> How long it takes to align sessions? <p>Much of the computation time is spent on calculating the neuron projections. However, this time is saved for subsequent analyses, as these images will be used during neuronal extraction. Completing the entire alignment process across four 10-minute sessions typically takes approximately 5 to 10 minutes.</p> Can I use different blood vessel sizes than those defined by default? <p>You can customize blood vessel parameters using the BV app.</p>"},{"location":"alignment/#output","title":"Output:","text":"<p>After running <code>align_sessions_CaliAli()</code> function the following files will be created:</p> <ul> <li>Several .h5 file with the \"_det\" suffix: These are the detrended and background removed version of each session. </li> <li>A single.h5 file with the \"_Aligned\" suffix: This is the concatenated data.</li> <li>Several .mat files: These files stores relevant variables for subsequent analysis.</li> </ul> <p></p>"},{"location":"alignment/#evaluating-alignment-performance","title":"Evaluating Alignment Performance:","text":"<p>During the execution of <code>align_sessions_CaliAli()</code>, you will see output similar to the following displayed in the command window:</p> <pre><code>Blood-vessel similarity score: 5.376\nCalculating correlation of the Neurons projections... \nProcessing:  100%  |############| 6/6it [00:00:00&lt;00:00:00, 32.27 it/s]\nCorrelation between Neurons projections is good! \nLowest spatial correlation: 0.491\n</code></pre> <p>The <code>Blood-vessel similarity score</code> reflects the usefulness of blood vessels in correcting inter-session misalignments. If this value falls below 2.7, CaliAli will issue a warning message and align sessions without relying on blood vessels (alignment dependent on neurons only).</p> <p>The <code>spatial correlation value</code> indicates the correlation of the aligned neurons' projections. If this value is below 0.2, it may suggest substantial differences in active neurons across sessions, possibly due to displacement in the z-axis.</p> <p>Next, To visually confirm the alignment performance, load the <code>*_Aligned.mat file</code> in MATLAB:</p> <p></p> <p>This will load the following components:</p> <ul> <li>BV_score: Blood-vessel similarity score</li> <li>Cn: Correlation image</li> <li>F: Number of frames in each session</li> <li>n_enhanced: Indicates whether MIN1PIE background subtraction was used</li> <li>opt: Structure containing relevant variables for subsequent analysis</li> <li>P: Table holding projections at different stages of the inter-session alignment process</li> <li>PNR: Peak-to-noise ratio image</li> </ul> <p>The most important components is the table P, which is structured as follow: </p> Column Description <code>Original</code> Projections before alignment <code>Translation</code> Projections after translation <code>Multi-Scale</code> Projections after multi-scale alignment <code>Final</code> Projections after final alignment <p>Each column contains a nested table with projections organized as 3D or 4D arrays, representing data from each session:</p> Column Description <code>Mean</code> Mean frame of each session <code>BloodVessels</code> Blood vessels projection of each session <code>Neurons</code> Neuron projections of each session <code>PNR</code> PNR projections of each session <code>BV+Neurons</code> Blood vessels and neurons projection of each session <p>You can visualize these projections with the following commands:</p> <p><pre><code>% Visualize BV+Neurons projection after alignment:\nimplay(P.(4)(1,:).(5){1,1});\n\n% Visualize BV+Neurons projection before alignment:\nimplay(P.(1)(1,:).(5){1,1});\n\n% Visualize BV+Neurons projection after translation:\nimplay(P.(2)(1,:).(5){1,1});\n\n% Visualize BV+Neurons projection after translation and after final registration:\nimplay(catpad(2,mat2gray(P.(2)(1,:).(5){1,1}),mat2gray(P.(4)(1,:).(5){1,1})))\n\n% Visualize Neurons projection after alignment:\nimplay(mat2gray(P.(4)(1,:).(3){1,1}));\n</code></pre> </p> Important <p>Please visually verify that sessions are correctly aligned. If you detect noticeable displacement in the field of view it means that CaliAli is not suitable for this data.</p> <p>After finishing inter-session aligment you can proceed to Extract Calcium Traces with CaliAli</p>"},{"location":"alignment/#processing-sessions-without-concatenation","title":"Processing Sessions without Concatenation:","text":"<p>You can also use CaliAli to process individual sessions without performing video concatenation. This is particularly useful for verifying signal quality between long-term experiments by processing individual sessions.</p> <p>To process sessions individually without concatenation, use the <code>detrend_batch_and_calculate_projections()</code> function instead of <code>align_sessions_CaliAli()</code>. The input parameters for <code>detrend_batch_and_calculate_projections()</code> are the same as those used for <code>align_sessions_CaliAli()</code>.</p> <p>Note</p> <p>The <code>detrend_batch_and_calculate_projections()</code> function also calculates projections for individual sessions. This information is stored in a <code>.mat</code> file created after running the function. If you decide to concatenate sessions later, you can then run <code>align_sessions_CaliAli()</code> as usual. CaliAli will automatically read the previously created <code>.mat</code> files and utilize the pre-calculated projections. You should see something like this in the command window:</p> <p><pre><code>align_sessions_CaliAli();\nObtaining registration borders and number of frames...\nProcessing:  100%  |############| 4/4it [00:00:01&lt;00:00:00, 3.80 it/s]\nCalculation of projections and detrending is already done for file \"H:\\My Drive\\GitHub\\CaliAli\\Demo\\v1_m_mc.h5\".\nCalculation of projections and detrending is already done for file \"H:\\My Drive\\GitHub\\CaliAli\\Demo\\v2_m_mc.h5\".\nCalculation of projections and detrending is already done for file \"H:\\My Drive\\GitHub\\CaliAli\\Demo\\v3_m_mc.h5\".\nCalculation of projections and detrending is already done for file \"H:\\My Drive\\GitHub\\CaliAli\\Demo\\v4_m_mc.h5\".\n</code></pre> *This require all files to be located in the same folder</p> Next <p>After finishing detrending individual files you can proceed to Extract Calcium Traces with CaliAli</p>"},{"location":"demo_data/","title":"Getting Started","text":"<p>This document provides guidance for running each module using four video sessions available in the CaliAli/Demos folder. However, you can apply these steps to your own data in a similar manner. Please note that the provided videos have already undergone motion correction. Details regarding the expected outputs of each module and their estimated running times are also included. </p> <p>Tip</p> <p>The raw calcium imaging videos described in the CaliAli paper can be found in the source data included with the manuscript.</p> About Hierarchical Data Format Version 5 <p>Note that CaliAli converts raw videos in .avi, .tiff, or .isdx format into .h5 during the downsampling process. Hierarchical Data Format (HDF5) allows loading several gigabytes of data in a few seconds and is ideal for processing multi-session data.</p>"},{"location":"demo_data/#caliali-processing-steps","title":"CaliAli Processing Steps","text":"<p>CaliAli requires executing the followin steps:</p> <ol> <li> <p>Downsampling and Motion correction</p> </li> <li> <p>Inter-session Alignment</p> </li> <li> <p>Signal extraction from concatenated sessions</p> </li> <li> <p>Post processing</p> </li> </ol> How long it takes to process the Demo data? <p>Processing the demo data is expected to take approximately 5-10 minutes on a standard desktop computer. This includes steps 2 to 4.</p> Next <p>To begin, proceed to Downsampling and Motion correction</p>"},{"location":"extraction/","title":"Calcium Signal Extraction with CaliAli","text":"<p>After confirming that no errors occur during session alignment and concatenation, you can proceed to extract neural signals.</p> <p>This process involves two steps:</p> <ol> <li> <p>Select Extraction Parameters for Each Session: Utilize a graphical user interface to set initialization thresholds.</p> </li> <li> <p>Run the CaliAli Extraction Module: Execute the CaliAli extraction module to extract neural signals.</p> </li> </ol>"},{"location":"extraction/#a-gui-for-parameter-selection","title":"A GUI for Parameter Selection","text":"<p>The extraction of calcium signals relies on an initial estimation of neuron locations based on two key projections: the correlation image (showing pixel correlations) and the peak-to-noise ratio (PNR) image (highlighting active regions in the video). To accurately identify candidate neurons, specific minimum correlation and PNR thresholds must be defined. These thresholds are essential for distinguishing genuine neuron activity from background noise and signal fluctuations.</p> <p>CaliAli offers a graphical user interface (GUI) for setting these thresholds visually.</p> <p>You can use this GUI by running the following code:</p> <p><code>CNMFe_app</code></p> <p>This will open a window that allows the user to choose one or more <code>.h5</code> file for processing:</p> <p></p> <p>For each loaded file the user can modify the following parameters:</p> <ol> <li>PNR threshold (PNR)</li> <li>Correlation threshold (Corr)</li> <li> <p>Neuron Filter size(gSig) (1).</p> <ol> <li>This parameter should match the settings used in previous steps. This will not be needed in future updates.</li> </ol> </li> <li> <p>Frame rate</p> </li> </ol> Info <p>You can process several files at the same time.</p>"},{"location":"extraction/#adjusting-pnr-and-corr-thresholds","title":"Adjusting PNR and Corr. Thresholds","text":"<p>To visually set the PNR and Corr. threshold press the <code>Get</code> button higlighted in green.</p> <p></p> Bug <p>Sometimes, the MATLAB AppDesigner app may not render panels correctly. This is a MATLAB bug. If this happens, just close and reopen the window to fix the issue.</p> <p>In the opened window, you will find three images displayed: the PNR image, the correlation image, and their point-wise product. Red dots overlaid on these images represent candidate neurons or \"seed pixels\". Below these images, there are two spinners that control the PNR and correlation thresholds. Adjusting these thresholds will change the number of seed pixels detected.</p> <p></p> <p>Additionally, you have the option to manually draw a mask to exclude specific regions within the field of view:</p> <p></p> Note <p>Currently you can only draw the mask in the correlation image.</p> Important <p>Please note that the initialization of neurons depends solely on the third panel, which is the point-wise product of the correlation and PNR (peak-to-noise ratio). Even if some seeds appear above non-neuronal structures in either the correlation or PNR images, this will not compromise the extraction process as long as those seeds do not appear in the point-wise product image</p> <p>Once satisfied with the results press the <code>Ok!</code> button. This will automatically update the parameters for the chosen file with the new thresholds. </p> <p>After setting the PNR, Corr, gSig, and Frame rate parameters press <code>Done!</code> This will create a table named <code>parin</code> (parameters inputs) in the matlab workspace. </p> Info <p>Some parameters specific to CNMF-E are pre-defined in the <code>runCNMFe.mat</code> code and typically do not require modifications.  Refer to the original CNMF-E documentation for details.</p>"},{"location":"extraction/#extracting-calcium-signals","title":"Extracting Calcium Signals","text":"<p>After defining input parameters perform neuronal extraction by running the following command:</p> <p><pre><code>CNMFe_batch(parin)\n</code></pre> This will start processing each file in the parin table using the specified parameters.</p> <p>The neuronal extraction process can be described by the following diagram:</p> <p><pre><code>graph TD;\n    A[CNMFe_batch] --&gt; B[Distribute data in patches];\n    B --&gt; C[Initialization];\n    C --&gt; |Checkpoint| D[Update Background];\n    D --&gt; E[Update Spatial];\n    E --&gt; F[Update Temporal];\n    F --&gt; G[Remove False-positives];\n    G --&gt; H[Merge Neurons];\n    H --&gt; I[Similarity Check];\n    I --&gt;|&lt;0.95| D;\n    I --&gt;|&gt;0.95&lt;br&gt;Checkpoint| J[Post-process Traces];\n    J --&gt; |Checkpoint| K[Manually Remove FP];\n    K --&gt; L[Manually Merge Neurons];\n    L --&gt; M[Pickup from Residual?];\n    M --&gt;|Yes| D;\n    M --&gt;|No| Finish;   \n\n    O[Optional];\n    P[Automatic];\n    N[Automatic CNMF];\n\nstyle A fill:none, stroke:none;\nstyle D stroke:#1CC90E, color:#00129A,  stroke-width:2px;\nstyle E stroke:#1CC90E, color:#00129A,  stroke-width:2px;\nstyle F stroke:#1CC90E, color:#00129A,  stroke-width:2px;\nstyle G stroke:#1CC90E, color:#00129A,  stroke-width:2px;\nstyle H stroke:#1CC90E, color:#00129A,  stroke-width:2px;\nstyle N stroke:#1CC90E, color:#00129A,  stroke-width:2px;\n\nstyle K stroke:#E04C3B, color:#7A6A68,  stroke-width:2px; \nstyle L stroke:#E04C3B, color:#7A6A68,  stroke-width:2px;\nstyle M stroke:#E04C3B, color:#7A6A68,  stroke-width:2px;\nstyle O stroke:#E04C3B, color:#7A6A68,  stroke-width:2px;</code></pre> During the execution of this code, you will see messages in the command window reflecting the steps depicted above. For example:</p> <pre><code>----------------UPDATE BACKGROUND---------------------------\nProcessing:  100%  |############| 4/4it [00:00:04&lt;00:00:00, 1.06 it/s]\n\n-----------------UPDATE SPATIAL---------------------------\nProcessing:  100%  |############| 4/4it [00:00:02&lt;00:00:00, 1.45 it/s]\n\n-----------------UPDATE TEMPORAL---------------------------\nProcessing:  100%  |############| 4/4it [00:00:05&lt;00:00:00, 1.30 s/it]\nDeconvolve and denoise all temporal traces again...\n</code></pre> How does CaliAli deconvolve calcium signals? <p>CaliAli employs the original FOOPSI method with an AR(1) autoregressive model for initialization and matrix factorization (which is faster). During the final post-processing of traces, a thresholded FOOPSI approach with an AR(2) model is utilized (which is slower but more accurate). Learn more in the OASIS documentation.</p> <p>Note that there are three checkpoints during this process: one after Initialization, another after CNMF iterations, and a third after Post-processing of Calcium Traces.</p> <p>The checkpoint files will be created as follows: </p> <pre><code>.\n\u2514\u2500 &lt;\"file_name\"&gt;_aligned_source_extraction/\n   \u2514\u2500 frames_&lt;\"xxx\"&gt;/\n      \u2514\u2500 LOGS_&lt;\"DATE\"&gt;/\n         \u251c\u2500 &lt;\"DATE-TIME\"&gt;.mat \"Checkpoint #1\"\n         \u251c\u2500 &lt;\"DATE-TIME\"&gt;.mat \"Checkpoint #2\"\n         \u251c\u2500 &lt;\"DATE-TIME\"&gt;.mat \"Checkpoint #3\"\n</code></pre> <p>Loading any of these checkpoint files will load a <code>neuron</code> object containing the following properties:</p> <p><pre><code>   A: [27840\u00d7106 double]\n   A_prev: [27840\u00d7106 double]\n   C: [106\u00d74000 double]\n   C_prev: [106\u00d74000 double]\n   C_raw: [106\u00d74000 double]\n   S: [106\u00d74000 double]\n   kernel: [1\u00d71 struct]\n   b0: {2\u00d74 cell}\n   b0_new: [120\u00d7232 double]\n   ...\n</code></pre>  Here the most important properties are:</p> <ol> <li> <p>A: Spatial components of neurons stored as a matrix d1*d2xN (1)</p> <ol> <li>d1 and d2 are the x and y dimensions of the field of view and N is the number of neurons.</li> </ol> </li> <li> <p>C_raw: Extracted raw calcium traces stored as a matrix NxT (1)</p> <ol> <li>N is the number of neurons and T is the number of frames. Fluorescent signals are expressed as SD above the noise level. This is what we use as raw dF/F0.  </li> </ol> </li> <li> <p>C: Denoised Calcium Signals. Same structure as C_raw.</p> </li> <li> <p>S: Raising events or Spikes. Same structure as C_raw. (1)</p> <ol> <li>This dataset contains the same information as dataset C, excluding the calculated rise and decay times of the calcium signals. S is recommended for most analyses.</li> </ol> </li> </ol> Next <p>After reaching the third checkpoint, the corresponding <code>.mat</code> file needs to be loaded into <code>MATLAB</code> to post-process and verify the quality of the extracted signals.</p>"}]}